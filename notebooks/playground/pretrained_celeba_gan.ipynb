{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "953ee502-bce6-4d19-96e3-7fd6b480da5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab117d2d-9740-4b19-ae71-395cfd3a0d5f",
   "metadata": {},
   "source": [
    "# Predictor\n",
    "\n",
    "Here, we will instantiate a standard image pretrained model, and use it as our \"oracle\" for\n",
    "performing rejection sampling during generating the CausalCelebA dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4febe428-6408-4ecb-9a63-81162951d535",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictorPipeline(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        cared_list=[\"all\"],\n",
    "        dat_root=None,\n",
    "        lr=0.01,\n",
    "        batch_size=100,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.cared_list = cared_list\n",
    "\n",
    "        model = torchvision.models.resnet18(pretrained=True)\n",
    "        num_features = model.fc.in_features\n",
    "        model.fc = nn.Linear(\n",
    "            num_features, 2 ** len(cared_list)\n",
    "        )  # multi-class classification (num_of_class == 307)\n",
    "        self.model = model\n",
    "\n",
    "        if dat_root:\n",
    "            self.dat_root = dat_root\n",
    "        else:\n",
    "            self.dat_root = \"dat/CelebAMask-HQ\"\n",
    "        # model = model.to(device)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        transforms_train = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((256, 256)),\n",
    "                transforms.RandomHorizontalFlip(),  # data augmentation\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "                ),  # normalization\n",
    "            ]\n",
    "        )\n",
    "        train_set = CelebAMaskHQDataset(\n",
    "            root=self.dat_root,\n",
    "            norm=True,\n",
    "            transform=transforms_train,\n",
    "            env=\"train\",\n",
    "            cared_list=self.cared_list,\n",
    "        )\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_set, batch_size=self.batch_size, shuffle=True, drop_last=True\n",
    "        )\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        transforms_test = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((256, 256)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "        test_set = CelebAMaskHQDataset(\n",
    "            root=self.dat_root,\n",
    "            norm=True,\n",
    "            transform=transforms_test,\n",
    "            env=\"test\",\n",
    "            cared_list=self.cared_list,\n",
    "        )\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            test_set, batch_size=self.batch_size, shuffle=True, drop_last=True\n",
    "        )\n",
    "        return test_loader\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=0.01, momentum=0.9)\n",
    "        lr_scheduler = ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": lr_scheduler,\n",
    "            \"monitor\": \"val_loss\",\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        outputs = self.model(x)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "\n",
    "        outputs = self.model(x)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        corrects = torch.sum(preds == y.data)\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True)\n",
    "        return corrects\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        total_corrects = torch.sum(torch.tensor(outputs)) / (\n",
    "            self.batch_size * len(outputs)\n",
    "        )\n",
    "        print(f\"acc at epoch {self.current_epoch} is {total_corrects.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5512f0b2-b981-4b02-af54-429e121a5565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/facebookresearch/pytorch_GAN_zoo/zipball/hub\" to /Users/adam2392/.cache/torch/hub/hub.zip\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/gan_zoo/PGAN/celebaHQ16_december_s7_i96000-9c72988c.pth\" to /Users/adam2392/.cache/torch/hub/checkpoints/celebaHQ16_december_s7_i96000-9c72988c.pth\n",
      "100%|████████████████████████████████████████████████████████████████████████| 264M/264M [00:16<00:00, 16.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average network found !\n"
     ]
    }
   ],
   "source": [
    "gen_model = torch.hub.load(\n",
    "    \"facebookresearch/pytorch_GAN_zoo:hub\",\n",
    "    \"PGAN\",\n",
    "    model_name=\"celebAHQ-512\",\n",
    "    pretrained=True,\n",
    "    useGPU=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efacecea-1891-45a0-8ab9-c8ad160730f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_save_path = Path(\"/Users/adam2392/Downloads/Pretrain-Gen/\")\n",
    "image_save_path.mkdir(exist_ok=True)\n",
    "num_images = 10\n",
    "\n",
    "noise, _ = gen_model.buildNoiseData(num_images)\n",
    "with torch.no_grad():\n",
    "    generated_images = gen_model.test(noise)\n",
    "\n",
    "# Resize transformation\n",
    "resize_transform = transforms.Resize((64, 64))\n",
    "\n",
    "for i in range(num_images):\n",
    "    # Apply the resize transform\n",
    "    resized_image = resize_transform(generated_images[i])\n",
    "\n",
    "    # Normalize the image (clamp and scale to [0, 1])\n",
    "    image_to_save = (resized_image.clamp(min=-1, max=1) + 1) / 2\n",
    "\n",
    "    save_image(\n",
    "        (generated_images[i, :, :, :].clamp(min=-1, max=1) + 1) / 2,\n",
    "        image_save_path / f\"{i + 1}.png\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938d3937-c4ac-40ed-983c-9c4abe939871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ciflows",
   "language": "python",
   "name": "ciflows"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
