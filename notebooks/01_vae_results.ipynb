{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import lightning as pl\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class plFFFConvVAE(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder,\n",
    "        decoder,\n",
    "        latent,\n",
    "        lr=3e-4,\n",
    "        lr_min: float = 1e-8,\n",
    "        lr_scheduler=None,\n",
    "        hutchinson_samples=2,\n",
    "        beta=1.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # ensure that the model is saved and can be loaded later as a checkpoint\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.latent = latent\n",
    "\n",
    "        self.lr = lr\n",
    "        self.lr_min = lr_min\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.hutchinson_samples = hutchinson_samples\n",
    "        self.beta = torch.Tensor([beta])\n",
    "\n",
    "    def forward(self, x, target=None):\n",
    "        \"\"\"Foward pass.\"\"\"\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        if self.lr_scheduler == \"cosine\":\n",
    "            # cosine learning rate annealing\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                optimizer,\n",
    "                T_max=self.trainer.max_epochs,\n",
    "                eta_min=self.lr_min,\n",
    "                verbose=True,\n",
    "            )\n",
    "        elif self.lr_scheduler == \"step\":\n",
    "            # An scheduler is optional, but can help in flows to get the last bpd improvement\n",
    "            scheduler = optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.99)\n",
    "        else:\n",
    "            scheduler = None\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        B = x.size(0)\n",
    "        # get the surrogate loss, latent representation, and reconstructed tensor\n",
    "        surrogate_loss, v_hat, x_hat = volume_change_surrogate(\n",
    "            x,\n",
    "            self.encoder,\n",
    "            self.decoder,\n",
    "            hutchinson_samples=self.hutchinson_samples,\n",
    "        )\n",
    "        # compute reconstruction loss\n",
    "        loss_reconstruction = torch.nn.functional.mse_loss(x_hat, x)\n",
    "\n",
    "        # get negative log likelihoood\n",
    "        v_hat = v_hat.view(B, -1)\n",
    "        loss_nll = -self.latent.log_prob(v_hat).mean() - surrogate_loss\n",
    "\n",
    "        loss = self.beta * loss_reconstruction + loss_nll\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, num_samples=1, **params):\n",
    "        \"\"\"\n",
    "        Sample a batch of images from the flow.\n",
    "        \"\"\"\n",
    "        # sample latent space and reshape to (batches, 1, embed_dim)\n",
    "        v = self.latent.sample(num_samples, **params)\n",
    "        v = v.reshape(num_samples, 1, -1)\n",
    "        return self.decoder(v)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        B = x.size(0)\n",
    "        self.beta = self.beta.to(x.device)\n",
    "\n",
    "        # get the surrogate loss, latent representation, and reconstructed tensor\n",
    "        surrogate_loss, v_hat, x_hat = volume_change_surrogate(\n",
    "            x,\n",
    "            self.encoder,\n",
    "            self.decoder,\n",
    "            hutchinson_samples=self.hutchinson_samples,\n",
    "        )\n",
    "        # compute reconstruction loss\n",
    "        loss_reconstruction = torch.nn.functional.mse_loss(x_hat, x).to(x.device)\n",
    "\n",
    "        # get negative log likelihoood\n",
    "        v_hat = v_hat.view(B, -1)\n",
    "        loss_nll = -self.latent.log_prob(v_hat).mean() - surrogate_loss\n",
    "\n",
    "        loss = self.beta * loss_reconstruction + loss_nll\n",
    "        # Print the loss to the console\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"val_loss: {loss}\")\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the model from checkpoint\n",
    "root = Path('/Users/adam2392/pytorch_data/ciflows/vae/results/')\n",
    "\n",
    "model_dir = root / 'check_fif_convvae_mnist_v1'\n",
    "model_dir = root / 'check_fif_convvae_mnist_latentdim12_v2'\n",
    "model_dir = root / 'check_fif_convvae_mnist_latentdim12_beta5_v3'\n",
    "model_dir = root / 'check_fif_convvae_mnist_latentdim128_beta5_v2'\n",
    "\n",
    "epoch = 209\n",
    "step=45150\n",
    "model_fname = model_dir / f'epoch={epoch}-step={step}.ckpt'\n",
    "# checkpoint = torch.load(model_fname, map_location='mps')\n",
    "\n",
    "model = plFFFConvVAE.load_from_checkpoint(model_fname)\n",
    "# print(checkpoint.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# samples = sample_from_vae(model, n_samples=16, latent_dim=16)\n",
    "samples = model.sample(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 122, 122])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_samples = 16\n",
    "\n",
    "# Visualize generated samples\n",
    "grid_size = make_grid(samples, nrow=4, padding=2)\n",
    "save_image(grid_size, 'generated_samples.png', normalize=False)\n",
    "\n",
    "print(grid_size.shape)\n",
    "fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
    "for i in range(num_samples):\n",
    "    ax = axes[i // 4, i % 4]\n",
    "    ax.imshow(samples[i].squeeze(), cmap='gray')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(1.1539, grad_fn=<SelectBackward0>) tensor(-152.7195, grad_fn=<SelectBackward0>)\n",
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(-1.3288, grad_fn=<SelectBackward0>) tensor(-140.7669, grad_fn=<SelectBackward0>)\n",
      "\n",
      "InjectiveGlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Injective1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(0.4206, grad_fn=<SelectBackward0>) tensor(-201.8108, grad_fn=<SelectBackward0>)\n",
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(-1.9168, grad_fn=<SelectBackward0>) tensor(-213.2499, grad_fn=<SelectBackward0>)\n",
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(1.7461, grad_fn=<SelectBackward0>) tensor(-219.1881, grad_fn=<SelectBackward0>)\n",
      "\n",
      "InjectiveGlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Injective1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(1.1374, grad_fn=<SelectBackward0>) tensor(-242.4399, grad_fn=<SelectBackward0>)\n",
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(-0.0893, grad_fn=<SelectBackward0>) tensor(-238.4351, grad_fn=<SelectBackward0>)\n",
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(3.6716, grad_fn=<SelectBackward0>) tensor(-262.5523, grad_fn=<SelectBackward0>)\n",
      "\n",
      "InjectiveGlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Injective1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(3.1844, grad_fn=<SelectBackward0>) tensor(-589.5147, grad_fn=<SelectBackward0>)\n",
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(8, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(-0.4904, grad_fn=<SelectBackward0>) tensor(-327.0146, grad_fn=<SelectBackward0>)\n",
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(8, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(1.9903, grad_fn=<SelectBackward0>) tensor(-734.1501, grad_fn=<SelectBackward0>)\n",
      "\n",
      "Squeeze() tensor(1.9903, grad_fn=<SelectBackward0>) tensor(-734.1501, grad_fn=<SelectBackward0>)\n",
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(-1.4663, grad_fn=<SelectBackward0>) tensor(-inf, grad_fn=<SelectBackward0>)\n",
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(1.4635, grad_fn=<SelectBackward0>) tensor(nan, grad_fn=<SelectBackward0>)\n",
      "\n",
      "Squeeze() tensor(1.4635, grad_fn=<SelectBackward0>) tensor(nan, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (1581086800.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[35], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    return z, log_q\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "num_samples = 2\n",
    "\n",
    "z, log_q = model.model.q0(num_samples)\n",
    "for flow in model.model.flows:\n",
    "    z, log_det = flow(z)\n",
    "    log_q -= log_det\n",
    "    print()\n",
    "    print(flow, z.flatten()[0], log_q[0])\n",
    "return z, log_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ciflows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
