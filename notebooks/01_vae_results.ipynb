{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import lightning as pl\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class plFFFConvVAE(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder,\n",
    "        decoder,\n",
    "        latent,\n",
    "        lr=3e-4,\n",
    "        lr_min: float = 1e-8,\n",
    "        lr_scheduler=None,\n",
    "        hutchinson_samples=2,\n",
    "        beta=1.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # ensure that the model is saved and can be loaded later as a checkpoint\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.latent = latent\n",
    "\n",
    "        self.lr = lr\n",
    "        self.lr_min = lr_min\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.hutchinson_samples = hutchinson_samples\n",
    "        self.beta = torch.Tensor([beta])\n",
    "\n",
    "    def forward(self, x, target=None):\n",
    "        \"\"\"Foward pass.\"\"\"\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        if self.lr_scheduler == \"cosine\":\n",
    "            # cosine learning rate annealing\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                optimizer,\n",
    "                T_max=self.trainer.max_epochs,\n",
    "                eta_min=self.lr_min,\n",
    "                verbose=True,\n",
    "            )\n",
    "        elif self.lr_scheduler == \"step\":\n",
    "            # An scheduler is optional, but can help in flows to get the last bpd improvement\n",
    "            scheduler = optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.99)\n",
    "        else:\n",
    "            scheduler = None\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        B = x.size(0)\n",
    "        # get the surrogate loss, latent representation, and reconstructed tensor\n",
    "        surrogate_loss, v_hat, x_hat = volume_change_surrogate(\n",
    "            x,\n",
    "            self.encoder,\n",
    "            self.decoder,\n",
    "            hutchinson_samples=self.hutchinson_samples,\n",
    "        )\n",
    "        # compute reconstruction loss\n",
    "        loss_reconstruction = torch.nn.functional.mse_loss(x_hat, x)\n",
    "\n",
    "        # get negative log likelihoood\n",
    "        v_hat = v_hat.view(B, -1)\n",
    "        loss_nll = -self.latent.log_prob(v_hat).mean() - surrogate_loss\n",
    "\n",
    "        loss = self.beta * loss_reconstruction + loss_nll\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, num_samples=1, **params):\n",
    "        \"\"\"\n",
    "        Sample a batch of images from the flow.\n",
    "        \"\"\"\n",
    "        # sample latent space and reshape to (batches, 1, embed_dim)\n",
    "        v = self.latent.sample(num_samples, **params)\n",
    "        v = v.reshape(num_samples, 1, -1)\n",
    "        return self.decoder(v)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        B = x.size(0)\n",
    "        self.beta = self.beta.to(x.device)\n",
    "\n",
    "        # get the surrogate loss, latent representation, and reconstructed tensor\n",
    "        surrogate_loss, v_hat, x_hat = volume_change_surrogate(\n",
    "            x,\n",
    "            self.encoder,\n",
    "            self.decoder,\n",
    "            hutchinson_samples=self.hutchinson_samples,\n",
    "        )\n",
    "        # compute reconstruction loss\n",
    "        loss_reconstruction = torch.nn.functional.mse_loss(x_hat, x).to(x.device)\n",
    "\n",
    "        # get negative log likelihoood\n",
    "        v_hat = v_hat.view(B, -1)\n",
    "        loss_nll = -self.latent.log_prob(v_hat).mean() - surrogate_loss\n",
    "\n",
    "        loss = self.beta * loss_reconstruction + loss_nll\n",
    "        # Print the loss to the console\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"val_loss: {loss}\")\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the model from checkpoint\n",
    "root = Path('/Users/adam2392/pytorch_data/ciflows/vae/results/')\n",
    "\n",
    "model_dir = root / 'check_fif_convvae_mnist_v1'\n",
    "epoch = 134\n",
    "step=58050\n",
    "model_fname = model_dir / f'epoch={epoch}-step={step}.ckpt'\n",
    "# checkpoint = torch.load(model_fname, map_location='mps')\n",
    "\n",
    "model = plFFFConvVAE.load_from_checkpoint(model_fname)\n",
    "# print(checkpoint.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# samples = sample_from_vae(model, n_samples=16, latent_dim=16)\n",
    "samples = model.sample(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 122, 122])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_samples = 16\n",
    "\n",
    "# Visualize generated samples\n",
    "grid_size = make_grid(samples, nrow=4, padding=2)\n",
    "save_image(grid_size, 'generated_samples.png', normalize=True)\n",
    "\n",
    "print(grid_size.shape)\n",
    "fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
    "for i in range(num_samples):\n",
    "    ax = axes[i // 4, i % 4]\n",
    "    ax.imshow(samples[i].squeeze(), cmap='gray')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(1.1539, grad_fn=<SelectBackward0>) tensor(-152.7195, grad_fn=<SelectBackward0>)\n",
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(-1.3288, grad_fn=<SelectBackward0>) tensor(-140.7669, grad_fn=<SelectBackward0>)\n",
      "\n",
      "InjectiveGlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Injective1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(0.4206, grad_fn=<SelectBackward0>) tensor(-201.8108, grad_fn=<SelectBackward0>)\n",
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(-1.9168, grad_fn=<SelectBackward0>) tensor(-213.2499, grad_fn=<SelectBackward0>)\n",
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(1.7461, grad_fn=<SelectBackward0>) tensor(-219.1881, grad_fn=<SelectBackward0>)\n",
      "\n",
      "InjectiveGlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Injective1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(1.1374, grad_fn=<SelectBackward0>) tensor(-242.4399, grad_fn=<SelectBackward0>)\n",
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(-0.0893, grad_fn=<SelectBackward0>) tensor(-238.4351, grad_fn=<SelectBackward0>)\n",
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(3.6716, grad_fn=<SelectBackward0>) tensor(-262.5523, grad_fn=<SelectBackward0>)\n",
      "\n",
      "InjectiveGlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Injective1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(3.1844, grad_fn=<SelectBackward0>) tensor(-589.5147, grad_fn=<SelectBackward0>)\n",
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(8, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(-0.4904, grad_fn=<SelectBackward0>) tensor(-327.0146, grad_fn=<SelectBackward0>)\n",
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(8, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(1.9903, grad_fn=<SelectBackward0>) tensor(-734.1501, grad_fn=<SelectBackward0>)\n",
      "\n",
      "Squeeze() tensor(1.9903, grad_fn=<SelectBackward0>) tensor(-734.1501, grad_fn=<SelectBackward0>)\n",
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(-1.4663, grad_fn=<SelectBackward0>) tensor(-inf, grad_fn=<SelectBackward0>)\n",
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(1.4635, grad_fn=<SelectBackward0>) tensor(nan, grad_fn=<SelectBackward0>)\n",
      "\n",
      "Squeeze() tensor(1.4635, grad_fn=<SelectBackward0>) tensor(nan, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (1581086800.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[35], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    return z, log_q\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "num_samples = 2\n",
    "\n",
    "z, log_q = model.model.q0(num_samples)\n",
    "for flow in model.model.flows:\n",
    "    z, log_det = flow(z)\n",
    "    log_q -= log_det\n",
    "    print()\n",
    "    print(flow, z.flatten()[0], log_q[0])\n",
    "return z, log_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ciflows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
