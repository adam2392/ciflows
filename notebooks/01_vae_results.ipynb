{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import lightning as pl\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class plFFFConvVAE(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder,\n",
    "        decoder,\n",
    "        latent,\n",
    "        lr=3e-4,\n",
    "        lr_min: float = 1e-8,\n",
    "        lr_scheduler=None,\n",
    "        hutchinson_samples=2,\n",
    "        beta=1.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # ensure that the model is saved and can be loaded later as a checkpoint\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.latent = latent\n",
    "\n",
    "        self.lr = lr\n",
    "        self.lr_min = lr_min\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        self.hutchinson_samples = hutchinson_samples\n",
    "        self.beta = torch.Tensor([beta])\n",
    "\n",
    "    def forward(self, x, target=None):\n",
    "        \"\"\"Foward pass.\"\"\"\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.lr)\n",
    "        if self.lr_scheduler == \"cosine\":\n",
    "            # cosine learning rate annealing\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "                optimizer,\n",
    "                T_max=self.trainer.max_epochs,\n",
    "                eta_min=self.lr_min,\n",
    "                verbose=True,\n",
    "            )\n",
    "        elif self.lr_scheduler == \"step\":\n",
    "            # An scheduler is optional, but can help in flows to get the last bpd improvement\n",
    "            scheduler = optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.99)\n",
    "        else:\n",
    "            scheduler = None\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        B = x.size(0)\n",
    "        # get the surrogate loss, latent representation, and reconstructed tensor\n",
    "        surrogate_loss, v_hat, x_hat = volume_change_surrogate(\n",
    "            x,\n",
    "            self.encoder,\n",
    "            self.decoder,\n",
    "            hutchinson_samples=self.hutchinson_samples,\n",
    "        )\n",
    "        # compute reconstruction loss\n",
    "        loss_reconstruction = torch.nn.functional.mse_loss(x_hat, x)\n",
    "\n",
    "        # get negative log likelihoood\n",
    "        v_hat = v_hat.view(B, -1)\n",
    "        loss_nll = -self.latent.log_prob(v_hat).mean() - surrogate_loss\n",
    "\n",
    "        loss = self.beta * loss_reconstruction + loss_nll\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, num_samples=1, **params):\n",
    "        \"\"\"\n",
    "        Sample a batch of images from the flow.\n",
    "        \"\"\"\n",
    "        # sample latent space and reshape to (batches, 1, embed_dim)\n",
    "        v = self.latent.sample(num_samples, **params)\n",
    "        v = v.reshape(num_samples, 1, -1)\n",
    "        return self.decoder(v)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        B = x.size(0)\n",
    "        self.beta = self.beta.to(x.device)\n",
    "\n",
    "        # get the surrogate loss, latent representation, and reconstructed tensor\n",
    "        surrogate_loss, v_hat, x_hat = volume_change_surrogate(\n",
    "            x,\n",
    "            self.encoder,\n",
    "            self.decoder,\n",
    "            hutchinson_samples=self.hutchinson_samples,\n",
    "        )\n",
    "        # compute reconstruction loss\n",
    "        loss_reconstruction = torch.nn.functional.mse_loss(x_hat, x).to(x.device)\n",
    "\n",
    "        # get negative log likelihoood\n",
    "        v_hat = v_hat.view(B, -1)\n",
    "        loss_nll = -self.latent.log_prob(v_hat).mean() - surrogate_loss\n",
    "\n",
    "        loss = self.beta * loss_reconstruction + loss_nll\n",
    "        # Print the loss to the console\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"val_loss: {loss}\")\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam2392/miniforge3/envs/ciflows/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['encoder'])`.\n",
      "/Users/adam2392/miniforge3/envs/ciflows/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'decoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['decoder'])`.\n",
      "/Users/adam2392/miniforge3/envs/ciflows/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:208: Attribute 'latent' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['latent'])`.\n"
     ]
    }
   ],
   "source": [
    "# reload the model from checkpoint\n",
    "root = Path('/Users/adam2392/pytorch_data/ciflows/vae/results/')\n",
    "\n",
    "model_dir = root / 'check_fif_convvae_mnist_v1'\n",
    "model_dir = root / 'check_fif_convvae_mnist_latentdim12_v2'\n",
    "\n",
    "epoch = 279\n",
    "step=120400\n",
    "model_fname = model_dir / f'epoch={epoch}-step={step}.ckpt'\n",
    "# checkpoint = torch.load(model_fname, map_location='mps')\n",
    "\n",
    "model = plFFFConvVAE.load_from_checkpoint(model_fname)\n",
    "# print(checkpoint.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# samples = sample_from_vae(model, n_samples=16, latent_dim=16)\n",
    "samples = model.sample(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 122, 122])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_samples = 16\n",
    "\n",
    "# Visualize generated samples\n",
    "grid_size = make_grid(samples, nrow=4, padding=2)\n",
    "save_image(grid_size, 'generated_samples.png', normalize=False)\n",
    "\n",
    "print(grid_size.shape)\n",
    "fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
    "for i in range(num_samples):\n",
    "    ax = axes[i // 4, i % 4]\n",
    "    ax.imshow(samples[i].squeeze(), cmap='gray')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(1.1539, grad_fn=<SelectBackward0>) tensor(-152.7195, grad_fn=<SelectBackward0>)\n",
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(-1.3288, grad_fn=<SelectBackward0>) tensor(-140.7669, grad_fn=<SelectBackward0>)\n",
      "\n",
      "InjectiveGlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Injective1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(0.4206, grad_fn=<SelectBackward0>) tensor(-201.8108, grad_fn=<SelectBackward0>)\n",
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(-1.9168, grad_fn=<SelectBackward0>) tensor(-213.2499, grad_fn=<SelectBackward0>)\n",
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(1.7461, grad_fn=<SelectBackward0>) tensor(-219.1881, grad_fn=<SelectBackward0>)\n",
      "\n",
      "InjectiveGlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Injective1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(1.1374, grad_fn=<SelectBackward0>) tensor(-242.4399, grad_fn=<SelectBackward0>)\n",
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(-0.0893, grad_fn=<SelectBackward0>) tensor(-238.4351, grad_fn=<SelectBackward0>)\n",
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(3.6716, grad_fn=<SelectBackward0>) tensor(-262.5523, grad_fn=<SelectBackward0>)\n",
      "\n",
      "InjectiveGlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Injective1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(3.1844, grad_fn=<SelectBackward0>) tensor(-589.5147, grad_fn=<SelectBackward0>)\n",
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(8, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(-0.4904, grad_fn=<SelectBackward0>) tensor(-327.0146, grad_fn=<SelectBackward0>)\n",
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(8, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(1.9903, grad_fn=<SelectBackward0>) tensor(-734.1501, grad_fn=<SelectBackward0>)\n",
      "\n",
      "Squeeze() tensor(1.9903, grad_fn=<SelectBackward0>) tensor(-734.1501, grad_fn=<SelectBackward0>)\n",
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(-1.4663, grad_fn=<SelectBackward0>) tensor(-inf, grad_fn=<SelectBackward0>)\n",
      "\n",
      "GlowBlock(\n",
      "  (flows): ModuleList(\n",
      "    (0): AffineCouplingBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): Split()\n",
      "        (1): AffineCoupling(\n",
      "          (param_map): ConvNet2d(\n",
      "            (net): Sequential(\n",
      "              (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "              (1): LeakyReLU(negative_slope=0.0)\n",
      "              (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "              (3): LeakyReLU(negative_slope=0.0)\n",
      "              (4): Conv2d(64, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): Merge()\n",
      "      )\n",
      "    )\n",
      "    (1): Invertible1x1Conv()\n",
      "    (2): ActNorm()\n",
      "  )\n",
      ") tensor(1.4635, grad_fn=<SelectBackward0>) tensor(nan, grad_fn=<SelectBackward0>)\n",
      "\n",
      "Squeeze() tensor(1.4635, grad_fn=<SelectBackward0>) tensor(nan, grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (1581086800.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[35], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    return z, log_q\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "num_samples = 2\n",
    "\n",
    "z, log_q = model.model.q0(num_samples)\n",
    "for flow in model.model.flows:\n",
    "    z, log_det = flow(z)\n",
    "    log_q -= log_det\n",
    "    print()\n",
    "    print(flow, z.flatten()[0], log_q[0])\n",
    "return z, log_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ciflows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
